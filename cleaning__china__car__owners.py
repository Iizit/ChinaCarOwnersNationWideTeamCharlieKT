# -*- coding: utf-8 -*-
"""Cleaning _China _Car_ owners

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1OSWPVns3YZhxRTB6jI_flMmmTzpDpEcD

**Create a Dictionary and Translate the Column Heads**
"""

import pandas as pd

# Define the translation dictionary
translation_dict = {
    "车架号": "Vehicle Identification Number (VIN)",
    "姓名": "Name",
    "身份证": "ID Card",
    "性别": "Gender",
    "手机": "Mobile Phone",
    "邮箱": "Email",
    "省": "Province",
    "城市": "City",
    "地址": "Address",
    "邮编": "Postal Code",
    "生日": "Date of Birth",
    "行业": "Industry",
    "月薪": "Monthly Salary",
    "婚姻": "Marital Status",
    "教育": "Education",
    "BRAND": "Brand",
    "车系": "Vehicle Series",
    "车型": "Vehicle Model",
    "配置": "Configuration",
    "颜色": "Color",
    "发动机号": "Engine Number"
}

# File path
file_path = "/content/760k-Car-Owners-Nationwide-China-csv-2020.csv"

# Read the CSV file
df = pd.read_csv(file_path)

# Rename the columns using the translation dictionary
df.rename(columns=translation_dict, inplace=True)

# Save the modified DataFrame to a new CSV file
output_file_path = "/content/translated_car_owners.csv"
df.to_csv(output_file_path, index=False)

print(f"Translated CSV saved to {output_file_path}")

""" print first 5 heads, last 5 tails of new csv"""

# prompt: Using the file path "/content/translated_car_owners.csv" write a code to print the first 5 heads and the last 5 tail

import pandas as pd

# File path
file_path = "/content/translated_car_owners.csv"

# Read the CSV file
df = pd.read_csv(file_path)

# Print the first 5 rows (head)
print("First 5 rows:")
print(df.head())

# Print the last 5 rows (tail)
print("\nLast 5 rows:")
print(df.tail())

"""Deduplicate ID CARD, MOBILE PHONE, EMAIL"""

# prompt: using the file path "/content/translated_car_owners.csv" extract and Remove duplicates from the columns "Id Card, Vehicle Identification Number(VIN), Email" and export the duplicales too a new file named "dump 0" and update the "/content/translated_car_owners.csv" to duplicate dropped car owners

import pandas as pd

# File path
file_path = "/content/translated_car_owners.csv"

# Read the CSV file
df = pd.read_csv(file_path)

# Identify duplicates based on 'ID Card', 'Vehicle Identification Number(VIN)', 'Email'
duplicate_rows = df[df.duplicated(subset=['ID Card', 'Vehicle Identification Number (VIN)', 'Email'], keep=False)]

# Export duplicates to a new file named "dump 0"
duplicate_rows.to_csv('/content/dump 0.csv', index=False)

# Remove duplicates from the original DataFrame, keeping the first occurrence
df_deduped = df.drop_duplicates(subset=['ID Card', 'Vehicle Identification Number (VIN)', 'Email'], keep='first')

# Save the updated DataFrame to the original file, overwriting the existing data
df_deduped.to_csv(file_path, index=False)

print("Duplicates exported to '/content/dump 0.csv'")
print("Updated CSV with duplicates removed saved to '/content/translated_car_owners.csv'")

"""Drop Columns"""

# prompt: using the file path "/content/translated_car_owners.csv "  apply the code columns_to_drop = [
# 'gender'
# ,
# 'industry'
# ,
# 'monthly_salary'
# ,
# 'marital_status'
# ,
# 'education'
# ,
# 'brand'
# ,
# 'car_series'
# ,
# 'car_model'
# ,
# 'configuration'
# ,
# 'color'
# ,
# 'engine_number'
# ,
# 'Unnamed: 21'
# ]   extract the columns and place in a new csv dumps 1 and update "/content/translated_car_owners.csv"

import pandas as pd

# File path
file_path = "/content/translated_car_owners.csv"

# Columns to drop
columns_to_drop = [
    'gender',
    'industry',
    'monthly_salary',
    'marital_status',
    'education',
    'brand',
    'car_series',
    'car_model',
    'configuration',
    'color',
    'engine_number',
    'Unnamed: 21'
]

# Read the CSV file
df = pd.read_csv(file_path)

# Drop the specified columns
df_dropped = df.drop(columns=columns_to_drop, errors='ignore')

# Save the updated DataFrame to a new file named "dump 1"
df_dropped.to_csv('/content/dump 1.csv', index=False)

# Update the original file with the dropped columns
df_dropped.to_csv(file_path, index=False)

print("Columns dropped and saved to '/content/dump 1.csv'")
print("Updated CSV with dropped columns saved to '/content/translated_car_owners.csv'")

# prompt: Write a code to seperate "/content/translated_car_owners.csv" into 8 chunks

import pandas as pd

def split_csv(file_path, num_chunks):
  """Splits a CSV file into multiple chunks.

  Args:
    file_path: The path to the CSV file.
    num_chunks: The number of chunks to split the file into.
  """

  df = pd.read_csv(file_path)
  chunk_size = len(df) // num_chunks
  for i in range(num_chunks):
    start_index = i * chunk_size
    end_index = (i + 1) * chunk_size if i < num_chunks - 1 else len(df)
    chunk = df.iloc[start_index:end_index]
    chunk.to_csv(f'/content/chunk_{i}.csv', index=False)

# Example usage
file_path = '/content/translated_car_owners.csv'
num_chunks = 8
split_csv(file_path, num_chunks)

"""**Check Chunks using a loop for invaliv emails**"""

# prompt: using the file path "/content/China Carowner Chunks" create a loop using chunk 0 all the way to chunk 7 and check the column "Email" for invalid email adresses and extract them and place them in a csv called dumpinvalidemails

import pandas as pd
import re

def is_valid_email(email):
  """Checks if an email address is valid using a regular expression."""
  pattern = r"^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}$"
  return re.match(pattern, email) is not None

invalid_emails = []

for chunk_num in range(8):
  try:
    df = pd.read_csv(f'/content/chunk_{chunk_num}.csv')

    for email in df['Email']:
      if not pd.isnull(email) and not is_valid_email(email):
        invalid_emails.append(email)

  except FileNotFoundError:
    print(f"Chunk {chunk_num} not found.")


# Create a DataFrame from the list of invalid emails
invalid_emails_df = pd.DataFrame({'Invalid Email': invalid_emails})

# Save the DataFrame to a CSV file
invalid_emails_df.to_csv('/content/dumpinvalidemails.csv', index=False)

print("Invalid email addresses extracted and saved to '/content/dumpinvalidemails.csv'")

"""Merge Chunks"""

# prompt: using the file path "/content/China Carowner Chunks" merge all chunks in the folder and name the export merged_China_CarOwners

import pandas as pd
import os

def merge_chunks(folder_path, output_file_name):
  """Merges all CSV chunks in a folder into a single CSV file.

  Args:
    folder_path: The path to the folder containing the chunks.
    output_file_name: The name of the output merged CSV file.
  """
  all_chunks = []
  for filename in os.listdir(folder_path):
    if filename.endswith(".csv"):
      file_path = os.path.join(folder_path, filename)
      try:
        df = pd.read_csv(file_path)
        all_chunks.append(df)
      except pd.errors.EmptyDataError:
        print(f"Warning: Empty CSV file found: {file_path}")

  if all_chunks:
    merged_df = pd.concat(all_chunks, ignore_index=True)
    merged_df.to_csv(output_file_name, index=False)
    print(f"Merged CSV saved to {output_file_name}")
  else:
    print("No CSV chunks found in the specified folder.")


# Example usage
folder_path = "/content/China Carowner Chunks"
output_file_name = "/content/merged_China_CarOwners.csv"
merge_chunks(folder_path, output_file_name)

# prompt: using the file path "/content/merged_China_CarOwners.csv" where the value "noemail" exist in the column email replace it with the value "Null", also write a function to check the "Vehicle Identification Number(VIN)" and "ID CARD" columns for alphanumeric characters and if the rows do not contain them add the rows missing them into a csv called dump 2 and update "/content/merged_China_CarOwners.csv"

import pandas as pd
import re
import os

# ... (Your existing code) ...


# Function to check for alphanumeric characters in VIN and ID Card columns
def check_alphanumeric(df):
  dump2_rows = []
  for index, row in df.iterrows():
    vin = str(row['Vehicle Identification Number (VIN)'])
    id_card = str(row['ID Card'])
    if not vin.isalnum() or not id_card.isalnum():
      dump2_rows.append(row)
  return dump2_rows

# Replace "noemail" with "Null" in the "Email" column
file_path = "/content/merged_China_CarOwners.csv"
df = pd.read_csv(file_path)
df['Email'] = df['Email'].replace('noemail', 'Null')

# Check for alphanumeric characters in VIN and ID Card columns
dump2_rows = check_alphanumeric(df)

# Create a DataFrame from the rows missing alphanumeric characters
dump2_df = pd.DataFrame(dump2_rows)

# Save the DataFrame to "dump 2.csv"
dump2_df.to_csv('/content/dump 2.csv', index=False)

# Remove rows missing alphanumeric characters from the original DataFrame
df = df[~df.index.isin(dump2_df.index)]

# Update "/content/merged_China_CarOwners.csv" with the filtered DataFrame
df.to_csv(file_path, index=False)

print("Rows missing alphanumeric characters saved to '/content/dump 2.csv'")
print("Updated CSV with filtered rows saved to '/content/merged_China_CarOwners.csv'")

# prompt: using the file path "/content/merged_China_CarOwners.csv" merge the columns "Providence" "city" and "postal code" into the "Address" Column and update to a new csv called Valid data

import pandas as pd

# File path
file_path = "/content/merged_China_CarOwners.csv"

# Read the CSV file
df = pd.read_csv(file_path)

# Create a new "Address" column by merging "Province", "City", and "Postal Code"
df['Address'] = df['Province'].astype(str) + ', ' + df['City'].astype(str) + ', ' + df['Postal Code'].astype(str)

# Drop the original "Province", "City", and "Postal Code" columns
df = df.drop(['Province', 'City', 'Postal Code'], axis=1)

# Save the modified DataFrame to a new CSV file
output_file_path = "/content/Valid_data.csv"
df.to_csv(output_file_path, index=False)

print(f"CSV with merged address saved to {output_file_path}")